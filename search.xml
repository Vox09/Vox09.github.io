<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Differential Equation]]></title>
    <url>%2F2019%2F04%2F10%2FDifferential-Equation%2F</url>
    <content type="text"><![CDATA[First OrderLinearfirst order linear equation standard form: {dy\over dt}+p(t)y=g(t)​In some cases it is possible to solve a first order linear equation immediately byintegrating the equation.Unfortunately, most of them should use a method called integrating factor. \mu(t){dy\over dt}+\mu(t)p(t)y=\mu(t)g(t)where ${d\mu\over dt}=p(t)\mu(t)$ so that $\mu(t)=ce^{G(t)}$ where $G(t) = \int g(t)$ SeparableM(x)dx+N(y)dy=0We can directly integral both sides to get the solution. Second Order Linear{d^2y\over dt^2}=f(t,y,{dy\over dt})Linear if $f(t,y,{dy\over dt})=g(t)-p(t){dy\over dt} -q(t)y$ Homogenous EquationWhen $g(t)=0$ the second order linear equation is said to be homogenous y''+p(t)y'+q(t)y=0Constant CoefficientsA second order linear homogenous equation with constant ay’’+by’+cy=0has characteristic equation ar^2+br+c=0The roots $r_1$ and $r_2$ correspond to $y_1=e^{r_1}$ and $y_2=e^{r_2}$Any linear combination of $y_1$ and $y_2$ is a solution. The distribution of the roots have three conditions Two distinct real roots. Just exponential function Two distinct complex roots. By, Euler’s formula, exponential of complex number is Sinusoids. Two identical real roots$r_0$. Then the solution is $y_1=e^{r_0t}\quad y_t=te^{r_0t}$. We can get this result by assume $y_2=v(t)y_1$ and finally we can find $v(t)=c_1+c_2t$ WronskianWhen given a initial point $y_0$, we have the equations: c_1y_1(t_0)+c_2y_2(t_0)=y_0\\ c_1y_1’(t_0)+c_2y_2’(t_0)=y_0’The Wronskian determinant is defined as W=\begin{vmatrix}y_1&y_2\\y_1’&y_2’\end{vmatrix} = y_1y_2’+y_1’y_2It is a function of independent variable t. Thus, different t correspond to different W. If at a point $t=t_0\quad W(t_0)\ne0$ the solution is unique. The constants are c_1={\begin{vmatrix}y_0&y_2(t_0)\\y_0’&y_2’(t_0)\end{vmatrix} \over W(t_0)} \quad c_2={-\begin{vmatrix}y_0&y_1(t_0)\\y_0’&y_1’(t_0)\end{vmatrix}\over W(t_0)}For the equation $y_0=c_1y_1+c_2y_2$ If at a point $t=t_0\quad W(t_0)=0$ the initial conditions cannot be satisfied not matter how $c_1$ and $c_2$ are chosen. $y=c_1y_1(t)+c_2y_2(t)$ is called the general solution.$y_1$ and $y_2$ are said to form a fundamental set of solutions if Wronskian is nonzero. Abel TheoremIf $y_1$ and $y_2$ are solutions of L[y]=y’’+p(t)y’+q(t)y=0Where p and q are continuous on an open interval $I$, then the Wronskian is given by W(y_1,y_2)(t)=c e^{-\int p(t)dt}Therefore, $W(y_1,y_2)(t)$ is either zero or else is never zero for all t in the interval. Nonhomogeneous EquationsA nonhomogenous equation is L[y]=y’’+p(t)y’+q(t)y=g(t)\ne 0We can solve it by thee steps: Find the general solution $c_1y_1(t) +c_2y_2(t)$ of the corresponding homogenous equation. Find some single solution $Y(t)$ of the nonhomogenous equation. Often this solution is referred to as a particular solution. Form the sum of the functions found in steps 1 and 2. Method of Undetermined CoefficientsMake an initial assumption about the form of the particular solution $Y(t)$. But with the coefficients left unspecified.e.g. for $y’’-3y’-4y=3e^{2t}$ we guess that $Y(t)=Ae^{2t}$ and finally obtain $A=-{1\over 2}​$]]></content>
      <categories>
        <category>Matters All THings</category>
      </categories>
      <tags>
        <tag>ODE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Probability]]></title>
    <url>%2F2019%2F03%2F21%2FProbability%2F</url>
    <content type="text"><![CDATA[Random Experiments random experimentan experimental procedure and one or more measurements or observations. sample spacethe set of all possible outcomes. discrete sample space if the number of outcomes is countable continuous sample space if not countable eventcertain conditions for an outcome. It can be represented by a subset A of the sample space S An event A occurs if the outcome is a member of A. the certain event, S, consists of all outcomes. the null event, $\phi​$, contains no outcomes. An elementary event contains only one outcome. the set of all possible outcomes. Replacement and OrderingWe can choose $k$ objects from a set $A$ that has $n$ members indifferent ways Replacement: With replacement: after selecting an object and noting its identity, the object is put back before the next selection. Without replacement: the object is not put back before the next selection. Ordering: With ordering: the order in which we draw the objects is recorded Without ordering: only the identity and number of times each object is drawn is important Replacement ordering number of outcomes Y N - Y Y $n^k$ N N ${n\choose k}={n!\over (n-k)! k!}$ N Y ${n\choose k}k!={n!\over(n-k)!}$ Note: when with replacement and without ordering, outcomes are NOT equally probable. There are two ways to choose a same object. But they counts the same outcome. Sequential ExperimentsExperiments that involve repetitions or multiple participants can often be viewed as a sequence of sub-experiments.The sub-experiments can be identical or non-identical, dependent or independent. The individual sample spaces can be identical or non-identical.If the experiments are identical, the individual sample spaces are identical but not vice versa. Examples Tossing a coin n times: repetition independent identical sub-experiments identical individual sample spaces Checking the number of students sleeping in class: multiple participants independent? (maybe not. Others sleep then I sleep) identical individual sample spaces non-identical sub-experiments (Dalaos do not sleep but I do) Mean and MomentsDiscrete RVMeanExpectation/Mean of a RV (if the sum below converges absolutely) m_X = E[X]=\sum_{x\in S_x}xp_X(x) = \sum_k x_kp_X(x_k)​Expectation/Mean of a function of a RV $Z=g(x)​$ E[Z]=E[g(x)]=\sum_k g(x_k)p_X(x_k)​IMPORTANT$E[ag(X)+bh(x)+c]\\ = aE[g(X)]+bE[h(X)]+c\\ \ne ag(E[X])+bh(E[X])+c$ VarianceVar[X] = E[D^2]=E[(X-E[X])^2]\\Std[X]=\sqrt {Var[X]}Useful formula$Var[X] = E[X^2]-(E[X])^2 \\Var[cX] = c^2Var[X]$ MomentsThe Mean and variance are examples of the moments of a RV. The $n^{th}$ moment of a RV$E[X^n] = \sum_kx_k^np_X(x_k)$ The $n^{th}$ central moment of a RV$E[(X-E[X])^n] = \sum_k(x_k-E[X])^np_X(x_k)$ Important moments:1st moment, $E[X]$ is the Mean2nd central moment, $E[(x-E[x])^2]$ is the variance Continuous RVMeanExpectation/Mean of a continuous RV(if the integral below converges absolutely) E[X]=\int_{-\infty}^\infty xf_X(x)​Expectation/Mean of a function of a continuous RV E[Y] = \int_{-\infty}^\infty g(x)f_X(x)dxLinearity of ExpectationGenerally $E[\sum_i a_ig_i(X)]=\sum_i a_iE[g_i(X)] \ne \sum a_ig_i(E[X])$if $g_i$ are all linear, the the tree above equal. Variancesometime denoted as $\sigma_x^2$All same as Variance in discrete RV MomentsThe $n^{th}$ moment of a RV$E[X^n] = \int_{-\infty}^\infty x^nf_X(x)$ The $n^{th}$ central moment of a RV$E[(X-E[X])^n] = \int_{-\infty}^\infty(x-E[X])^nf_X(x_k)$ Important moments:1st moment, $E[X]$ is the Mean2nd central moment, $E[(x-E[x])^2]$ is the variance Minimum Mean Squared Error EstimationMSE(c) = E[(X-c)^2]=\int_{-\infty}^\infty(x-c)^2f_X(x)dxThus, the best guess is $c=E[X]$! Also, the variance is ten the minimum mean squared error associated with the best guess. Random VariablesDiscrete RVWe often use probability mass function(PMF) to describe the property of a Discrete RV. It is like a histogram. The summation of PMF, is called the cumulative distribution(CDF). CDF of discrete RV is discrete. It is like a series of stairs that always jumping up. Each edge contains the beginning point but exclude the ending point. Discrete RV also have probability density function(PDF). It is similar to PMF, just substitute the bar in histogram with a peak\arrow ($\delta(x-x_k)$) at the left point of an edge. BernoulliX only take two values, either 1 or 0. P_X[0] = 1-p\quad P_X[1] = p​Mean $E[X]=p​$Variance $Var[X] = p(1-p)​$ Usage: Single coin toss Occurrence of an event of interest BinomialThe number of times that an event occurs. P_X[k]={n\choose k} p^k(1-p)^{n-k}\quad\text{for k = 0,1,2...}Mean $E[X] = np​$Variance $Var[X]=np(1-p)​$ Usage: Multiple coin flips Occurrence of a property in individuals of a population(e.g. bit errors in a transmission) When $n\to\infty$ , turn to Poisson RV GeometricSuppose a random experiment is repeated, In each repeat, it occurs independently and with probability $p$ TrialsThe number of trials until the first success occurs. P_X[k]=(1-p)^{k-1}p\quad\text{for k = 1,2,...}​Mean $E[X]={1 \over p}$Variance $Var[X] = {1-p\over p^2}​$ FailuresThe number of failures before the first success, $X’ = X-1​$ is also a geometric RV. P_{X’}[k]=(1-p)^kp\quad\text{for k = 0,1,2...}​Mean $E[X‘]={1-p \over p}$Variance $Var[M’]={1-p\over p^2}$ Usage: Number of transmissions required until an error free transmission. Memoryless property:No matter how hard you ever tried, the probability to succeed remains the same. Uniform(discrete)Values in a set of integers are with equal probability. S_X=\{0,1,2...,M-1\}\\ P_X[k]={1\over M}\quad \text{for k }\in S_x​Mean $E[X] = {M-1\over 2}={a+b\over 2}$Variance $Var[X]={M^2-1\over 12}={(b-a+1)^2-1\over12}$ PoissonThe number of occurrences of an event in a certain interval of time or space. P_X[k]={\alpha^k \over k!}e^{-\alpha}\quad \text{for k=0,1,2...}​The parameter $\alpha​$ is the average number of events in the interval. Mean $E[N]=\alpha$Variance $Var[N]=\alpha$ Usage: Number of hits on a website in one hour number of particles emitted by a radioactive mass in a fixed time period Relationship with Binomial RV:For a Binomial random variable with $p = {\alpha\over n}$:$p_0=(1-p)^n = (1-{\alpha\over n})^n \to e^{-\alpha} \quad\text{as}\ n\to\infty$${p_{k+1}\over p_k} = {(n-k)p\over(k+1)(1-p)}={(1-k/n)\alpha\over(k+1)(1-\alpha/n)}$when$n\to\infty\quad{p_{k+1}\over p_k}={\alpha\over k+1}​$ Continuous RVFor continuous, probability density function(PDF) is like PMF for discrete RV. The integral of PDF, is called the cumulative distribution function(CDF). CDF of continuous RV is usually continuous, which means for any point $x=a\quad P[X=a] = 0​$. If there is a jump (discontinuous point) in CDF at $x=b​$, then it must be a discrete point where $P[X=b] = const​$. Uniform(continuous)Intervals of the same length on the domain have the same probability. S_X=[a,b]\\ f_X(x)={1\over {b-a}}\quad \text{for x }\in S_x\\ F_X(x)={x-a\over {b-a}}\quad \text{for x }\in S_xMean $E[X] = {a+b\over 2}​$Variance $Var[X]={(b-a)^2\over 12}​$ ExponentialThe length of time that wait next train. f_X(x)=\lambda e^{-\lambda x}\quad\text{when }x\gt 0\\ F_X(x)=1-e^{-\lambda x}\quad\text{when }x\gt 0​Mean $E[X]={1\over\lambda}​$Variance $Var[X] = {1\over \lambda^2}​$ Memoryless property:No matter how hard you ever wait, the probability to meet the right one remains the same. Gaussian(Normal)Variables that tend to occur around a certain value,m , the mean. f_X= {1\over \sqrt{2\pi}\sigma}e^{-(x-m)^2\over 2\sigma^2}\ ​we define the CDF of the”normalized” Gaussian with mean m=0 and standard deviation $\sigma=1​$ as \Phi(x)={1\over \sqrt{2\pi}}\int_{-\infty}^x e^{-t^2 \over 2}dt​Then the CDF of a Gaussian RV, $X​$, with mean $m​$ and standard deviation $\sigma​$ is F_X(x)=\Phi({x-m\over \sigma})={1\over \sqrt{2\pi}}\int_{-\infty}^{x-m\over\sigma} e^{-t^2 \over 2}dt​ Q-function$Q(x) = 1-\Phi(x)=P[X&gt;x]$By symmetry, $Q(0)={1\over 2}$ and $Q(x)=\Phi(-x)$ TransformationGiven a random variable $X$ with known distribution and a real valuedfunction $g(x)$, such that $Y = g(X)$ is also a random variable. Find thedistribution of $Y$. Key ideaTo find equivalent events in X for suitably defined events in Y. Approaches If Y is Discrete, find the PMF at the possible values of Y$p_Y(k) = P[Y=k]=P[\{X:g(X)=k\}]$ If Y is continuous, there are two approaches: Find the CDF of Y$F_Y(y)=P[Y\le y]=P[\{X:g(X)\le y\}]$ Find the PDF of Y$f_Y(y_0)=\sum_{x:g(x)=y}{f_X(x_)\over |g’(x)|}$VERY USEFUL $\uparrow\uparrow\uparrow\uparrow\uparrow​$ Conditional ProbabilityExclusive and Independent Mutually Exclusive $P[A\cap B] = 0\quad P[A\cup B]=P[A]+P[B]​$ Independent$P[A\cap B] = P[A]P[B] \quad P[A|B] = P[A]$Dependent$P[A\cap B] = P[A]P[B|A] = P[B]P[A|B]\quad P[A|B]={P[A\cap B]\over P[B]}​$ Total Probability Theorem:If $B_1,B_2,B_3…B_n$ partition the sample space, then for any event A, P[A] = \sum_{i=1}^n P[A|B_i]P[B_i]​This theorem lets us spilt the problem of computing the probability of A into smaller(easier) sub-problems! Bayes RuleIf $B_1,B_2,B_3…B_n$ be a partition of the sample space S, For an event A, P[B_j|A]={P[A\cap B_j]\over P[A]} = {P[A|B_j]P[B_j] \over \sum_{k=1}^n P[A|B_k]P[B_k]}Bayes’ Rule lets us switch which event is the conditioning event. PMF PDF CDFPMF $p_X(x|C)=P[X=x|C] = {P[\{X=x\}\cap C]\over P[C]}$ PDF $F_X(x|C)={P[\{X\le x\}\cap C]\over P[C]}$Using conditioning $F_X(x) = \sum_iF_X(x|B_i)P[B_i]$ CDF $f_X(x|C)={d\over dx}F_X(x|C)$Using conditioning $f_X(x)=\sum_if_x(x|B_i)P[B_i]$ Mean and VarianceMean m_{X|B}=E[X|B] = \sum_{x\in S_X}xp_X(x|B)=\sum_k x_kp_X(x_k|B)Variance Var[X|B]=E[X^2|B]-m^2_{X|B}Using conditioning to compute expectation E[X] = \sum_i E[X|B_i]P[B_i]]]></content>
      <categories>
        <category>Matters All THings</category>
      </categories>
      <tags>
        <tag>probability</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fourier Transform]]></title>
    <url>%2F2019%2F03%2F21%2FFourier-Transform%2F</url>
    <content type="text"><![CDATA[Fourier SeriesCTFSSynthesis Equationany T-periodic functions can be expressed by many Sinusoids x(t) = \sum_{k=-\infty}^{\infty} a_ke^{jk{2\pi\over T}t}​Analysis Equation CTcalculate the coefficients of each Sinusoids a_k = {1\over T}\int_{t\in T}x(t)e^{-jk\omega_0t}dtIntuitionthe analysis equation is a normalized inner product that computes a projection coefficient that specifies how much $x(t)$ projecting on $e^{jk\omega_0t}$ . The Projection isThe normalization process is DTFS$\omega_0 = {2\pi\over N}$ is the fundamental frequency$f_0 = {1 \over N}​$ is the fundamental frequency in ordinary frequency In DT, there are only N distinct harmonics with period N! Synthesis Equationa weighted sum of N complex sinusoids. x[n] = \sum_{k=0}^{N-1}a_k e^{jk({2\pi\over N})n}Analysis Equation DTcalculates the FS coefficients which are the weights for the harmonics. a_k = {1 \over N}\sum_{n=0}^{N-1}x[n]e^{-jk({2\pi \over N})n}==IMPORTANT NOTE==:for N is even, $a_{N\over 2} ​$ is definitely real. It has no conjugates. Properties Fourier TransformRegarding aperiodic signals as periodic signals in the limit of period T going to infinity. Recall that $a_k = {1\over T}\int_{t\in T}x(t)e^{-jk\omega_0t}dt$ is the projection coefficient that $x(t)$ on $e^{-jk\omega_0t}$.However, when $T\to\infty\quad a_k\to0$, so we define $X_T(j\omega)=\int_{-T/2}^{T/2}x(t)e^{-j\omega t}dt$.Therefore, $X_T(j{k2\pi\over T}) = Ta_k$ . We rewrite the Synthesis Equation with $\omega_0={2\pi\over T}$ : x(t) = \sum_{k=-\infty}^{\infty}{\omega_0\over 2\pi}X_T(jk\omega_0) e^{jk\omega_0t}as $T\to\infty\quad \omega_0\to0$, we can rewrite it in integral form. Synthesis Equationconsider the signal as a superposition of complex sinusoids with density x(t) = {1\over 2\pi}\int_{-\infty}^\infty X(j\omega)e^{j\omega t}d\omega = \mathcal{F}^{-1}\{X(j\omega)\} ​Analysis Equationcalculate the density of complex sinusoids with different frequency X(j\omega)=\int_{-\infty}^{\infty}x(t)e^{-j\omega t}dt = \mathcal{F}\{x(t)\}​Duality propertyThere is symmetry in the FT(Fourier Transform) and IFT(Inverse Fourier Transform) integrals.They are identical except for a factor $2\pi​$ and a change in sign. ExamplesWindow$x(t) = \text{window width }2T_1 \iff X(j\omega) = {2sin\omega T_1\over \omega}$ Complex Sinusoid$x(t) = e^{j\omega_0t} \iff X(j\omega) = 2\pi\delta(\omega-\omega_0)​$ Periodic SignalFT integral of a FS sum equals the sum of a FT integral. X(j\omega) = \int_{-\infty}^{\infty}(\sum_{k=-\infty}^\infty a_ke^{jk\omega_0t})e^{-j\omega t}dt = \sum_{k=-\infty}^\infty a_k\int_{-\infty}^{\infty}e^{jk\omega_0t}e^{-j\omega t}dt = \sum_{k=-\infty}^\infty a_k2\pi\delta(\omega-k\omega_0)Property]]></content>
      <categories>
        <category>Matters All THings</category>
      </categories>
      <tags>
        <tag>math</tag>
        <tag>Fourier</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Signal and System]]></title>
    <url>%2F2019%2F03%2F19%2FSignal%20and%20System%2F</url>
    <content type="text"><![CDATA[Fundamental SignalsCTComplex Exponentiale^{st} = e^{(\sigma+j\omega)t} = e^{\sigma t}e^{j\omega t}​Where $e^{\sigma t}​$ is purely real. $\sigma&gt;0​$ amplitude grows, $\sigma&lt;0​$ amplitude decays.$e^{j\omega t}​$ is purely imaginary and called Complex Sinusoids $e^{st}u(t)$ is right-sided complex exponential$e^{st}u(it)$ is left-sided complex exponential Unit Function$ u(t) = 1$ when $t\ge 0$$ u(t) = 0$ when $t\lt 0$ Impulse SignalDenoted by $\delta(t)$ u(t) = \int_{-\infty}^{t} \delta(\tau)d\tau \\ \delta(t) = {du(t)\over dt} Zero everywhere else, infinite at $t=0​$ Unit total area $\int_{-\infty}^{\infty} \delta(t)dt = 1​$ Integral is the unit step $u(t) = \int_{-\infty}^{\infty} \delta(\tau)d\tau​$ Scaled impulse k$\delta(t)$ has total area k. $\int_{-\infty}^{\infty} k\delta(t)dt = k\int_{-\infty}^{\infty}\delta(t)dt = k $ Sampling property $x(t)\delta(t) = x(0)\delta(t)$ Sifting property $\int_{-\infty}^{\infty}x(t)\delta(t-t_0)dt = x(t_0)$ Infinite energy. Therefore $\delta(t)$ is an idealization that cannot physically exist. Time Scaling corresponds to Magnitude Scaling $\delta(\alpha t) = {\delta(t)\over \left|{\alpha}\right|}$ DTReal Exponential$ \alpha^n = e^{\alpha n} $ where $\alpha = e^a$ $\alpha&gt;1$ growing exponential$0&lt;\alpha&lt;1$ decaying exponential$-1&lt;\alpha&lt;0$ decaying oscillating$\alpha&lt;-1$ growing oscillating Real Sinusoids$cos(\omega n) = cos(2\pi fn)$ Periodic only if its ordinary frequency $f$ is rational number $f$ and $f\pm m(integer)$ are the same frequency. $\omega$ and $\omega\pm m2\pi$ are the same frequency The fastest rate at which a DT signal can oscillate is at an ordinary frequency of $f={1\over2}$ or angular frequency of $\omega = \pi$ Complex Exponential$z^n$ where $z = e^s = e^{\sigma + j\omega} = e^\sigma e^{j\omega}$ $z^n = \left|z\right|^n e^{j\omega n}$$\left|z\right|^n$is real exponential $ e^{j\omega n}$ is complex sinusoid Complex Sinusoid$x[n] = e^{j\omega n} = cos \omega n + j sin \omega n$ Periodic iff $\omega = {m2\pi \over N}$ $e^{j\omega n} = e^{j(\omega +2k\pi)n}$ frequency is periodic for DT signal, and the highest angular frequency is $\pi$ CT and DT Complex Frequency $z = e^s$ Impulse Signal and Unit Function$u[n] = 1$ when $n\ge 0$$u[n] = 0$ when $n\lt 0$ $\delta[0] = 1$ other place 0.Property same as CT. SystemBasic System Characterization Memoryless: instantaneous Causality: does not depend on future Stability: BIBO(Bounded-Input Bounded Output) Invertibility: distinct inputs lead to distinct outputs Time-invariant Linearity Time InvarianceShifted input shifted output. Operation of time does not depends on time. $ y(t) = \int_{t-3}^{t+2} x(\tau)d\tau$ YES : 3 time before and 2 later$ y(t) = \int_{0}^{t} x(\tau)d\tau$ NO: has a beginning point 0 Linearity Additive property: $x_1(t) \to x_2(t) = y_1(t) \to y_2(t)$ Homogeneity (scaling): $ax_1(t) \to ay_1(t)$ Elementary Linear Operation: Differentiation and integration: $x^{(k)}(t)$ ( LTI! ) Time shifting:$x(t-\tau)$ ( LTI! ) Multiply by a function: $g(t)x(t)$ ( not TI unless $g(t)$ is constant) time reversal, time scaling ( not TI because there is a origin) Impulse ResponseDenoted by $h(t)$ or $h[n]$ If the output of a system is given by convolving the input with a $h[n]$, then the system is LTI! Convolution is LTI Typical Examples: $h[n] = \delta[n]$ identity function. Do nothing. $h[n] = \delta[n-m]​$ delay system. Delay the input by m. $h[n] = \delta[n]+0.3\delta[n-4]$ echo system. With echo volume 0.3. $h[n] = u[n]$ first sum system. $y[n] = \sum_{-\infty}^n x[k]$ $h[n] = {1\over 3} (u[n] - u[n-3]) = {1\over 3}(h[n] + h[h-1] + h[n-2])$ window smoother. $h[n] = \delta[n] -\delta[n-1]$ first difference system. DT formula $y[n] = \sum_{k=-\infty}^{\infty} x(k\Delta)\delta_\Delta(n)\Delta​$CT formula $y(t) = \int_{-\infty}^{\infty}x(\tau)\delta(t-\tau)d\tau​$ Properties and characterization of LTI SystemsConvolution/LTI properties: commutative $x(t) \ast h(t) = h(t) \ast x(t)​$ distributive $x(t) \ast\{h_1(t) + h_2(t)\} = x(t)\ast h_1(t) +x(t) \ast h_2(t)​$ associative$\{x(t)\ast h_1(t)\}\ast h_2(t) = x(t)\{h_1(t)h_2(t)\}$ Charactering LTI system by Impulse Responses: Memoryles &lt;=&gt; $h[n] = 0 ​$ for $n\ne0​$ Causality &lt;=&gt; $h[n] =0​$ for $n\lt0​$ Stability &lt;=&gt;impulse response is absolute integrable/summable $\int_{-\infty}^{\infty}\left|h(t)\right|dt \lt \infty​$ or $\sum_{n=-\infty}^{\infty}\left|h(t)\right|dt \lt \infty​$ System Function and Frequency Responsey[n] = \sum_{k=-\infty}^\infty h[k]x[n-k] = H(z)x[n] \\ H(z) = \sum_{k=-\infty}^{\infty} h[k]z^{-k}y(t) = \int_{\tau=-\infty}^\infty h(\tau)x(t-\tau) = H(s)x(t) \\H(s) = \int_{-\infty}^{\infty}h(\tau)e^{-s\tau}d\tau$z^n $/$ e^{sn}$ is an eigenfunction of DT/CT LTI systems. $H(z)$ or $H(s)$ is the eigenvalue that depends on the complex frequency $z$. They are also called system function of CT/DT LTI systems. $H(s)$ is a Laplace Transform of the CT impulse response $h(t)$$H(z)$ is a z-transform of the DT impulse response $h[n]$ For LTI System, the eigenvalue at different oscillation frequency $\omega$ is called frequency response H(s)e^{st} = H(j\omega)e^{j\omega t} where $H(j\omega)$ is the cross-section of $H(s)$ along $j\omega$ axis. H(z)z^{n} = H(e^{j\omega})e^{j\omega n} where $H(e^{j\omega})$is the value of system function $H(z)$ along the unit circle $z=e^{j\omega}$]]></content>
      <categories>
        <category>Signal is Everything</category>
      </categories>
      <tags>
        <tag>Fourier</tag>
        <tag>signal</tag>
        <tag>system</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shortest Paths and Flow]]></title>
    <url>%2F2018%2F12%2F15%2FShortest-Paths-and-Flow%2F</url>
    <content type="text"><![CDATA[Algorithm Comments Graph Rep Running time Space Used Bellman-Ford Single-Source Adj List 𝑂(𝑉𝐸) 𝑂(𝑉) In DAG Out DAG Single-Source DAG Adj List 𝑂(𝑉+𝐸) 𝑂(𝑉) Dijkstra Single-SourceNon-Neg Weights Adj List 𝑂((𝑉 + 𝐸)log𝑉) 𝑂(𝑉) All-pairs 1 All-Pairs Adj Matrix 𝑂(𝑉^4^) 𝑂(𝑉^2^) All-pairs 2 All-Pairs Adj Matrix 𝑂(𝑉^3^log𝑉) 𝑂(𝑉^2^) Floyd-Warshall All-Pairs Adj Matrix 𝑂(𝑉^3^) 𝑂(𝑉^2^) Shortest Paths All algorithms, except Dijkstra, allow negative weights,but there can NOT be negative cycle. Shortest path problem: Find the shortest path from s to t. Single-source shortest path: Find the shortest path from s to every node. Lemma (Cut and Paste Argument): Let 𝑃 = (𝑠, … , 𝑢, … , 𝑡) be the shortest 𝑠 − 𝑡 path. The n the subpaths 𝑃~1~ = (𝑠, … , 𝑢) and 𝑃2= (𝑢, . . 𝑡) must also be, respectively, shortest 𝑠 − 𝑢 and 𝑢 − 𝑡 paths. Relaxation: Let v.d be the shortest distance found so far from the starting node s to node v, and v.p be the last node in the current shortest path from s to node v. Single Source Shortest PathLet ss(s,v) store shortest path distance from s to v Bellman-Ford AlgorithmInitially, set n.d = inf for all nodes. Except starting node s.d = 0Relax all edges once … path length maximum 1Relax all edges second time … path length maximum 2 A path may have at most V-1 edges. So we it V-1 times. Finally, n.d is the actual shortest distance from s to n Basic Implementation1234567Shortest-Path(G,s):for each node n in V do n.d = infs.d = 0for i = 1 to V-1 for each edge (u,n) in E Relax(u,n) Running time: Θ(𝑉𝐸)Space: Θ(𝑉) Efficient ImplementationTake advantage of dynamic programming. Recurrence:Suppose (u,n) is the last edge of shortest path of length at most i from s to n. By cut and paste argument, the subpath from s to u must be a shortest path of length at most i - 1, followed by (u,n).So, for all i &gt; 0 and n != s n.d[i] = min{ u.d[i-1] + w(u,n) } u in V, (u,n) in E Final solution: n.d[m-1] 12345678910Bellman-Ford(G,s):for each node n in V n.d = inf, n.p = nils.d = 0for i = 1 to V-1 for each node u in V if u.d changed in previous iteration then for each un in Adj(u) Relax(u,un) if no un.d changed in this iteration =&gt; terminate Running time: Θ(𝑉𝐸)Space: Θ(𝑉) Shortest Paths in a DAGBy subpath optimality, we have ss(s,n) = min { ss(s,u) + w(u,n) } u in V, (u,v) in Es Unlike Bellman-Ford, each edge will only be relaxed once. We need to ensure that when n is processed, ALL u with (u,n) in E have already been processed. We can do that by processing n (also ss(s,n)) in the topological order of the nodes. 123456789DAG-Shortest-Path(G,s)topologically sort the vertices of Gfor each vertex n in V n.d = inf n.p = nils.d = 0for each vertex u in topological order for each vertex un in Adj(u) Relax(u,un) Running time: Θ(𝑉+𝐸) Dijkstra AlgorithmNOT allow negative weights. Maintain a set of explored nodes S for which we know u.d = ss(s,u)by variable status Initialize S = {s}, s.d = 0, v.d = inf Use a Min priority queueQ on V with d as key Key Lemma If all edges leaving S are relaxed, then v.d = ss(s,v),where v is the vertex in V-S with the minimum v.d So this v can be added to S, then repeat pseudocode123456789101112Dijkstra(G,s):for each node n in V do n.d = inf, n.p = nil, n.status = unknowns.d = 0create a min priority queue Q onV with d as keywhile Q not empty % E times u = Extract-Min(Q) % O(logV) time u.status = over for each un in Adj(u) do if un.status = unknown then Relax(u,un) Decrease-Key(Q,un,un.d) Running time: 𝑂(𝐸log𝑉)Very similar to Prim’s algorithm All-Pairs Shortest PathsInput: Directed graph G = (V,E) Weight w(e) = length of edge e Output: ss(u,v), for all pairs of nodes u, v A data structure from which the shortest path from 𝑢 to 𝑣 can be extracted efficiently, for any pair of nodes 𝑢, 𝑣 Note: Storing all shortest paths explicitly for all pairs requires 𝑂(𝑉^3^) space. Graph Representation: Assume adjacency matrix: 𝑤(𝑢, 𝑣) can be extracted in 𝑂(1) time. 𝑤(𝑢, 𝑢)= 0, 𝑤(𝑢, 𝑣)= ∞if there is no edge from 𝑢 to 𝑣. If the graph is stored in adjacency lists format, can convert to adjacency matrix in 𝑂(𝑉2) time. Using Previous AlgorithmsNOT negative cost edges: Dijkstra’s algorithmRunning time: 𝑂(𝐸 log 𝑉), totally 𝑂(𝑉𝐸 log 𝑉)Space: 𝑂 (𝑛^3^ log 𝑛 ) for dense graphs HAVE negative cost edges: Bellman-FordRunning time: 𝑂(𝑉𝐸), totally 𝑂(𝑉^2^𝐸)Space: 𝑂 (𝑛^4^) for dense graphs First DP FormulationDefine d(i,j,m) = length of the shortest path from i to j that contains at most m edges.Use D[m] to denote the matrix [d(i,j,m)] Recurrence( essentially the same as in Bellman-Ford): d(i,j,m) = min { d(i,k,m-1) + w(k,j) } k from 1 to ninitially d(i,j,1) = w(i,j) pseudocode1234567891011Slow-All-Pairs-Shortest-Paths(G):d(i,j,1) = w(i,j) for all 1&lt;=i,j&lt;=nfor m = 2 to n-1 let D[m] be a new n*n matrix for i = 1 to n for j = 1 to n d(i,j,m) = inf for l =1 to n if d(i,k,m-1) + w(k,j) &lt; d(i,j,m) then d(i,j,m) = d(i,k,m-1) + w(k,j)return D[n-1] Running time: 𝑂(𝑛^4^)Space: 𝑂(𝑛^3^) can be improved to 𝑂(𝑛^2^) Second DP FormulationObservationTo compute d(i,j,m), instead of looking at the last stop before j, we look at the middle point. This cuts down the problem size by half. Thus, to calculate D[1],D[2],D[4],D[8],… Note that overshooting D[n-1] is OK. Since D[n&#39;] , n&#39;&gt;n -1 has the shortest paths with up to n&#39; edges. It will not miss any shortest path with up to n-1 edges. Recurrence d(i,j,2s) = min { d(i,k,s) + d(k,j,s) } k from 1 to ninitially d(i,j,1) = w(i,j) AnalyzeRunning time: 𝑂(𝑛^3^) for each matrix , totally 𝑂(𝑛^3^log𝑛) Floyd-WarshallDefined(i,j,k) = length of the shortest path from i to j that all intermediate vertices on the path (if any) are in the set {1,2,...,k} ObservationWhen computing d(i,j,k) there are two cases: k is not a node on the shortest path from i to j=&gt; then the path uses only vertices in {1,2,...,k-1} k is an intermediate node on the shortest path from i to j=&gt; path can be spilt into shortest subpath from i to k and a subpath from k to jBoth subpaths use only vertices in {1,2,...,k-1} Recurrence pseudocode1234567891011Floyd-Warshall(G):d(i,j,0) = w(i,j) for all 1&lt;=i,j&lt;=nfor k=1 to n let D[k] be a new n*n matrix for i = 1 to n for j = 1 to n if d(i,k,k-1) + d(k,j,k-1) &lt; d(i,j,k-1) then d(i,j,k) = d(i,k,k-1) + d(k,j,k-1) else d(i,j,k) = d(i,j,k-1)return D[n] Running time: 𝑂(𝑛^3^)Space: 𝑂(𝑛^3^) but can be improved to 𝑂(𝑛^2^)Surprising discovery: If we just drop all third dimension. i.e. the algorithm just uses n*n array D, the algorithm still works! Maximum FlowInput: A directed connected graph 𝐺 =(𝑉, 𝐸) , where every edge 𝑒 ∈ 𝐸 has a capacity 𝑐(𝑒); a source vertex 𝑠 and a target vertex 𝑡. Output: A flow 𝑓: 𝐸 → 𝐑 from 𝑠 to 𝑡, such that For each 𝑒 ∈ 𝐸, 0 ≤ 𝑓(𝑒) ≤ 𝑐(𝑒) (capacity) For each 𝒗 ∈ 𝑽 − {𝒔, 𝒕}, sumOut( 𝒇(𝒆) ) = sumInto( 𝒇(𝒆) )(conservation)、 Define:The value of a flow is |𝑓| = sum(𝑓(𝑠, 𝑣))= sum(𝑓(𝑣, 𝑡)) where 𝑣 in V s-t Cut Residual Graph Ford Fulkerson Algorithm Start with f(e) = 0 for all edges e in E Construct Residual Graph G~f~ for current flow f(e) = 0 while there exists some s-t path P in G~f~ Let capacity of flow cf(p) = min { cf(e): e in P}This is the maximum amount of flow that can be pushed through residual capacity of P‘s edges Push c(f,p) units of flow along the edges e in P by adding cf(p) to f(e) for every e in P Construct Residual Graph G~f~ for new current flow f(e) When algorithm gets stuck, current flow is maximal! 12345678910111213141516Ford-Fulkerson(G,s,t):for each (u,n) in E do f(u,n) = 0 cf(u,n) = c(e) cf(n,u) = 0while there exists path P in residual graph Gf do cf(p) = min &#123;cf(e):e in P&#125; for each edge (u,n) in P do if (u,n) in E then f(u,n) = f(u,n) + cf(p) cf(u,n) = cf(u,n) - cf(p) cf(n,u) = cf(n,u) + cf(p) else f(n,u) = f(n,u) - cf(p) cf(n,u) = cf(n,u) + cf(p) cf(u,n) = cf(u,n) - cf(p) Construct Residual Graph G~f~ capacity of flow in 8, write back to G The G~f~ in next iteration is Until there is no s-t path in G~f~. Current flow is optimally maximal. Applicationshe Max Flow setup can model (surprisingly) many (seemingly) unrelated problems. The idea is to express the problem as a max flow and then feed individual instances into out max flow solver. The examples below all share the property that they are integer flow problems, e.g., al capacities are integral, so running-time analyses can use FF bound for integral flows. Edge-Disjoint Paths Define: Two paths are edge-disjoint if they have no edge in common. Circulations with Demands Given a number of source vertices 𝑠1, 𝑠2, …, each with a supply of 𝑠𝑢𝑝(𝑠𝑖)and a number of target vertices 𝑡1, 𝑡2, …, each with a demand of 𝑑𝑒𝑚 𝑡𝑖 ;sum of supply &gt;= sum of demand Need a flow meets all demands. Solution:Add a super source and a super target Maximum Bipartite Matching A Matching is a subset M ⊆ E such that:∀v ∈ V at most one edge in M is incident upon v. The Size |M| is the number of edges in M. A Maximum Matching is matching M such that:every other matching Mʹ satisfies |Mʹ | ≤ M. Given bipartite graph G, find a Maximum Matching. Formulation: Create directed graph 𝐺′ = (𝑋 ∪ 𝑌 ∪ {𝑠, 𝑡}, 𝐸′ ). Direct all edges from 𝑋 to 𝑌, and assign them capacity 1. Add source 𝑠, and unit capacity edges from 𝑠 to each node in 𝑋. Add target 𝑡, and unit capacity edges from each node in 𝑌 to 𝑡. Theorem: Max cardinality matching in 𝐺 = value of max flow in 𝐺′. Running time: 𝑂(𝑉𝐸) Baseball Elimination Input： 𝑛 teams: 1, 2, … , 𝑛 One particular team, say 𝑛 (without loss of generality) Team 𝑖 has won 𝑤~𝑖~ games already Team 𝑖 and 𝑗 still need to play 𝑟~𝑖𝑗~ games, 𝑟~𝑖𝑗~ = 0 or 1. Team 𝑖 has a total of 𝑟𝑖 = sum(𝑟~𝑖𝑗~: 𝑗) games to play Output: “Yes”, if there is an outcome for each remaining game such that team 𝑛 finishes with the most wins (tie is OK). “No”, if no such possibilities. Claim: There is a way for team n to finish in the first place iff the max flow has value of the sum of supply from source s]]></content>
      <categories>
        <category>Algorithm and Graph</category>
      </categories>
      <tags>
        <tag>searching</tag>
        <tag>algorithm</tag>
        <tag>graph</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Minimum Spanning Tree]]></title>
    <url>%2F2018%2F12%2F15%2FMinimum-Spanning-Tree%2F</url>
    <content type="text"><![CDATA[Uniqueness of MSTCut LemmaLet S be any subset of nodeslet e be the min cost edge with exactly one endpoint in S.Then every MST must contain e. ProofLet T* be some MSTConsider any edge e in T*Removing e from T* breaks T* into two parts Sand V-Se must be the min cost edge crossing the cut (S,S-V)Applying the cut lemma on S, every MST must contain eApply the above arguments to every edge in T*, we have_Every edge e in T* must be contained in every MST_ Prim’s Algorithm Idea Initialize explored set S = { any one node } Add min cost edge e = (u,n) with u in S and n in V-S to T Add n to S Repeat until S = V FeatureMaintain set of explored nodes S A Min priority queue Q to keep unknown nodes.key is their cheapest edge to node inS pseudocode12345678910111213Prim(G,r):for each n in V do n.key = inf, n.p = nil, n.status = unknownr.key = 0create a min priority queue Q on Vwhile Q not empty u = Extract-Min(Q) % need O(logV) time u.status = over for each n in Adj(u) do if n.status = unknown and w(u,n)&lt;n.key then n.p = u n.key = w(u,n) Decrease-Key(Q,n,w(u,n)) Running time: 𝑂(𝐸log𝑉) Kruskal’s Algorithm Idea Start with an empty tree T Consider edges in ascending order of weight. Case 1: If adding e to T create a cycle, discard eCase 2: Otherwise, insert e = (u,v) into T according to cut Lemma Union-Find Data StructureKey QuestionHow to check whether adding e to T will create a cycle? DFS take 𝑂(𝐸⋅𝑉) time in total.Can we do better in 𝑂(log𝑉) time? After an edge e is added, two sets union together Need such a “union-find”data structure: Find-Set(u): For a given node u, find which set this node belongs to. Union(u,v): For two given nodes u and v, merge the two sets containing u and v together. Set as A Tree The trees in the union-find data structure are NOT the same as the partial MST trees! The root of the tree is the representative node of all nodes in that tree(i.e., use the root’s ID as the unique ID of the set). Every node (except the root), has a pointer pointing to its parent. The root has a parent pointer to itself. No child pointers (unlike BST), so a node can have many children. 12Make-Set(x):x.parent = x, x.hight = 0 123456Find-Set(x):x.height = 0while x!= x.parent do x.height = x.height + 1 x= x.parentreturn x 12345678Union(x,y):a = Find-Set(x)b = Find-Set(y)if a.height &lt;= b.height then if a.height = b.height then b.height = b.height + 1 a.parent = belse b.parent = a Path Compressionwhile Find-Set(x) we can update its parent pointer to compress the path. pseudocode12345678MST-Kruskal(G):for each node n in V Make-Set(n)sort the edges of G into increasing order by weight % O(ElogE)for each edge (u,n) in E taken in the above order if Find-Set(u) != Find-Set(v) then % O(E) output edge (u,n) Union(u,n) Running time: 𝑂(𝐸log𝐸+𝐸log𝑉)=𝑂(𝐸log𝑉)Note: If edges are already sorted(𝑂(𝐸log𝐸)) and we use path compression, then the running time is close to 𝑂(𝐸)]]></content>
      <categories>
        <category>Algorithm and Graph</category>
      </categories>
      <tags>
        <tag>searching</tag>
        <tag>algorithm</tag>
        <tag>graph</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Graph Basic and Algorithm]]></title>
    <url>%2F2018%2F12%2F15%2FGraph-Basic-and-Algorithm%2F</url>
    <content type="text"><![CDATA[Basicnode: vertex edge: connection between nodes Undirected Edges have no direction (or both directions) deg (𝑣) = # edges at 𝑣 sum of deg(𝑣) = 2𝐸 Directed Edges have directions If an edge has both directions, we will use two edges with opposite directions deg~out~ (𝑣) = # edge leaving 𝑣;deg~in~ (𝑣 ) = # edge entering 𝑣. sum of deg𝑜𝑢𝑡(𝑣) = sum of deg𝑖𝑛(𝑣) = 𝐸 Path A path in a (directed or undirected) graph 𝐺 = (𝑉, 𝐸) is a sequence 𝑃 of nodes 𝑣1, 𝑣2, … , 𝑣𝑘−1, 𝑣𝑘 such that (𝑣𝑖, 𝑣𝑖+1) is an edge. The length of the path is 𝑘 − 1 (i.e., # edges in the path). A path is simple if all nodes are distinct. Connectivity An undirected graph is connected if for every pair of nodes 𝑢 and 𝑣, there is a path between 𝑢 and 𝑣. Theorem: For a connected graph, 𝐸 ≥ 𝑉 − 1. Cycle A cycle is a path v~1~, v~2~, … , v~k-1~, v~k~ in which v~1~ = v~k~ , k &gt; 2 A cycle is simple if the first 𝑘 − 1 nodes are all distinct. Data structureAdjacency Nodes Adjacency List A node-indexed array of lists. Given node 𝑢, retrieving all neighbors in Θ(deg(𝑢)) time Given 𝑢, 𝑣, checking if (𝑢, 𝑣) is an edge takes Θ(deg(𝑢)) time. Space: Θ(𝑉 + 𝐸). Adjacency Matrix A 𝑉 × 𝑉 matrix. Given node 𝑢, retrieving all neighbors in Θ (𝑉) time Given 𝑢, 𝑣, checking if (𝑢, 𝑣) is an edge takes 𝑂(1) time. Space: Θ(𝑉2). Treesconnected &amp;&amp; no cycle =&gt; treeno cycle =&gt; forest(several trees) After we have run BFS or DFS on an undirected graph, the edges can be classified into 3 types: Tree edges:traversed by the BFS/DFS Back edges:connecting a node with one of its ancestors(other than its parent) Cross edges:connecting two nodes with no ancestor/descendent relationship. AlgorithmBFS span a tree with NO back edges pseudo-code1234567891011initialize an empty queue QEnqueue(Q,r)while Q not empty do n = Dequeue(Q) for each v in Adj(n) if v.status = unknown v.status = processing v.d = n.d + 1 v.p = n Enqueue(Q,v) n.status = over Running time: Θ(𝑉+𝐸), which is Θ𝐸 if the graph is connected ApplicationFind connected components. DFS span a tree with NO cross edges pseudo-code123456789101112DFS(G)for each vertex n in V do if n.status = unknown then DFS-Visit(n)DFS-Visit(n):n.status = processingfor each v in Adj(n) do if v.status = unknown the v.p = n DFS-Vist(v)n.status = over Running time: Θ(𝑉+𝐸) ApplicationCycle detection Topological Sort A topological ordering of a graph is a linear ordering of the vertices of a DAG(Directed Acyclic Graph) such that if (u,v) is in the graph, u appears before v in the linear ordering. idea Output a vertex u with in-degree zero in current graph Remove u and all edges (u,v) from current graph If the graph is not empty, go to step 1 pseudo-code1234567891011121314Initialize Q to be an empty queuefor each u in V do If inDegree(u) = 0 then % find all starting vertices Enqueue(Q,u)while Q not empty u = Dequeue(Q); Output u for each v in Adj(u) % remove u&apos;s outgoing edges inDegree(v) = inDegree(v) - 1 if inDegree(v) = 0 then Enqueque(Q,v)return Running time: 𝑂(𝑉+𝐸)]]></content>
      <categories>
        <category>Algorithm and Graph</category>
      </categories>
      <tags>
        <tag>searching</tag>
        <tag>algorithm</tag>
        <tag>graph</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dynamic Programming]]></title>
    <url>%2F2018%2F12%2F15%2FDynamic-Programming%2F</url>
    <content type="text"><![CDATA[Main idea of DP: Analyze the structure of an optimal solution Recursively define the value of an optimal solution Compute the value of an optimal solution (usually bottom-up) @[TOC] One-DimensionStairs Climbing 1D You can climb 1 or 2 stairs with one step.How many different ways can you climb n stairs? Recurrence F(n) = F(n-1) + F(n-2) Base case F(1) = 1, F(2) = 2 pseudo-code1234567F(n):allocate an array A of size nA[1] = 1A[2] = 2for i=3 to n A[i] = A[i-1] + A[i-2]return A[n] AnalyzeRunning time: Θ(𝑛)Space: Θ(𝑛) but can be improved to Θ(1) by freeing array. Rod Cutting Problem Given a rod of length n and prices p~i~ for i = 1,…,n, where p~i~ is the price of a rod of length i . Find a way to cut the rod to maximize total revenue. length i 1 2 3 4 5 6 7 8 9 10 price p~i~ 1 5 8 9 10 17 17 20 24 30 Recurrencetotal optimal revenue is price of cut rod and optimal revenue of remaining rood. r~n~ = max{p~n~, p~1~ + r~n-1~, p~2~ + r~n-2~, …, p~n-1~+r~1~} Base caseDefine r~n~ be the maximum revenue obtainable from cutting a rod of length n. r~1~ = p~1~ pseudo-code123456789101112131415cutRod(n):let r[0...n] and s[0...n] be new arraysr[0] = 0 for j=1 to n % every optimal length q = -inf for i =1 to j % every cut length if q &lt; p[i] + r[j-i] then q = p[i]+r[j-i] % keep track the optimal cut length s[j] = i r[j] = qj = n while j&gt;0 do print s[j] j = j-s[j] i 0 1 2 3 4 5 6 7 8 9 10 p[i] 0 1 5 8 9 10 17 17 20 24 30 r[i] 0 1 5 8 9 13 17 18 22 25 30 s[i] 0 1 2 3 2 2 6 1 2 3 10 AnalysizeRunning time: Θ(𝑛^2^)Space: Θ(𝑛) Weighted Interval Scheduling 1D Jobs j starts at s~j~, finish at f~j~ and has weight(value) v~j~.Two jobs compatible if they don’t overlap.Goal: find maximum-weight subset if mutually compatible jobs. RecurrenceFirstly, label all jobs by finishing time. Maximum subset is eitherDO take this job and maximum subset of compatible jobs setNOT take this job and maximum subset of remaining jobs V[j] = max{v~j~ + V[c(j)], V[j-1]} function c(j) return the largest index i&lt;j such that job i is compatible job j. Base caseThe goal is to find a subset of a set. We start from a empty set. pseudo-code12345678910111213141516schedule():sort all jobs by finish timeV[0] = 0for i = 1 to n % DO take job j if V[i] + V[c(i)] &gt; V[j-1] then V[i] = value[i] + V[c(i)] keep[i] = 1 % NOT take job j else V[i] = V[i-1] keep[i] = 0 i = nwhile i &gt; 0 do if keep[i] =1 then print i, i = c(i) else i = i-1 AnalyzeRunning time: Θ(𝑛log𝑛)Space: Θ(𝑛) Two-DimensionSometimes sub-problem also need to use 1D-DP to solve.Sometimes there are two variables that requires a 2D array. The 0/1 Knapsack Problem A set of n items, where item i has weight w~i~ and value v~i~ ,and a knapsack with capacity W.Find x~1~,… ,x~n~ (either 0 or 1) such thatsum(x~i~w~i~) &lt;= W and V=sum(x~i~v~i~) is maximum RecurrenceStart to put items into the knapsack.—1D Maximum V of capacity W is the max among whether take each item.v~i~ + maximum XV of capacity j-w~i~We found it necessary to consider capacity of knapsack.**—2D** V[j] = max{v(i) + V[j-w(i)]} i from 1 to n WRONG: This may pick the same item more than once!Thus, both in v~i~ and V[j-w(i)]! New def: let V[i,j] be the largest obtained value with capacity j, choosing ONLY from the first i items.Below formula truly reflect whether. Left is NOT, right is YES. V[i,j] = max{V[i-1,j], v~i~ + V[i-1,j-w(i)]} i from i to n Base case We start from take nothing: i= 0, V[0,j] = 0and empty knapsack j =0, V[i,0] = 0 pseudo-code1234567891011121314let V[0...n,0...W] and keep[0...n,0...W] be new arrays of all 0 for i = 1 to n do % put things for j = 1 to W do % each capacity if w[i]&lt;=j and v[i]+V[i-1,j-w[i]] &gt; V[i-1,j] then V[i,j] = v[i]+V[i-1,j] keep[i,j] = 1 else V[i,j] = V[i-1,j] keelp[i,j] = 0K = Wfor i = n downto 1 do if keep[i,K] = 1 then print i K = K-w[i] input: i 1 2 3 4 v~i~ 10 40 30 50 w~i~ 5 4 6 3 running: V[i,j] 0 1 2 3 4 5 6 7 8 9 10 i=0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 10 10 10 10 10 10 2 0 0 0 0 40 40 40 40 40 40 40 3 0 0 0 0 40 40 40 40 40 50 70 4 0 0 0 50 50 50 50 90 90 90 90 AnalyzeRunning time: Θ(𝑛𝑊)Space: Θ(𝑛𝑊)without keep array can be improved to Θ(𝑛+𝑊). Longest Common Subsequence LCS Given two sequences X = (x~1~,x~2~,…,x~m~) and Y = (y~1~,y~2~,…,y~n~), we say that Z is a common subsequence of X and Y if Z has a strictly increasing sequence of indices i and j of both X and Y such that we have x~ip~= y~jp~ = z~p~ for all p = 1, 2, … , k. The goal is to find the longest common subsequence of X and Y. RecurrenceLet c[i,j] be the length of the longest common subsequence of X[1…i] and Y[1…j].So we need 2D that i for X and j for Y. Firstly, go through i, and then go through jIf X[i] = Y[j], we match.c[i,j] = 1 + the longest common subsequence of X[1…i-1] and Y[1…j-1].else , it’s max ofthe longest common subsequence of X[1…i-1] and Y[1…j] andthe longest common subsequence of X[1…i] and Y[1…j-1] If X[i] = Y[j] , c[i,j] = max{ c[i,i-1], c[i-1,j] } else c[i,j]= c[i-1,j-1] +1 Base case c[0,j] =0c[i,0] = 0 pseudo-code1234567891011121314151617181920212223LSC(X,Y):let c[0...m,0...n] and b[0...m,0...n] be new arrys of all 0for i=1 to m for j=1 to n if X(i) = Y(i) then c[i,j] = c[i-1,j-1]+1 b[i,j] = &quot;↖&quot; else if c[i-1,j] &gt;= c[i,j-1] then c[i,j] = c[i-1,j] b[i,j] = &quot;↑&quot; else c[i,j] = c[i,j-1] b[i,j] = &quot;←&quot;Print-LCS(b,m,n)Print-LCS(b,i,j): if i=0 or j=0 then return if b[i,j]=&quot;↖&quot; then Print-LCS (b,i−1,j−1) print X(i) else if 𝑏[𝑖,𝑗]=&quot;↑&quot; Print-LCS( b,i−1,j) else Print-LCS( b,i,j−1) AnalyzeRunning time: Θ(𝑚𝑛)Space: Θ(𝑚𝑛)without b array can be improved to Θ(𝑚+𝑛). Longest Common Substring Given two strings X = x~1~x~2~…x~m~ and Y = y~1~y~2~…y~m~, we wish to find their longest common substring Z, that is, the largest k for which there are indices 𝑖 and 𝑗 withx~i~x~i+1~…x~i+k-1~ = y~j~y~j+1~…y~j-k-1~ RecurrenceLet d[i,j] keep track of k, the longest string length of X[1…i] Y[1…j].Firstly go through X and then Y so we need 2D If X(i) = Y(j), d[i,j] = 1 + the longest string length of X[1…i-1] Y[1…j-1].else it’s 0! If X(i) = Y(j), d[i,j] = 1 + d[i-1.j-1]else d[i,j] = 0 Base case d[0,j] = 0, d[i,0]= 0 pseudo-code1234567891011let d[0...m,0...n] be a new array of all 0length = 0, endIndex = 0for i = 1 to m for j = 1 to n if X(i) = Y(i) then d[i,j] = d[i-1,j-1] + 1 if d[i,j] &gt; length then length = d[i,j] endIndex = ifor i = endIndex - length + to endIndex print X(i) AnalyzeRunning time: Θ(𝑚𝑛)Space: Θ(𝑚𝑛) but can be improved to Θ(𝑚+𝑛). Over Intervals Goal is to find optimal (min or max ) solution on problem with Problem of size n Ordered input of items 1,2,…n Define substructures as Ordered input of items i..j Problem of size j-i+1 Recurrence gives optimal solution of subproblem as function of optimal solution of smaller subproblems Algorithm fills in DP table from smallest to largest problem size Often, final subproblem filled is solution for original problemSometimes, solution of original problem is min/max over table values Longest Palindromic SubstringA palindrome is a string that reads the same backward or forward. Given a string X = x~1~x~2~…x~n~, find the longest palindromic substring. Ex:X =ACCABAPalindromic substrings: CC, ACCA ABALongest palindromic substrings: ACCA RecurrenceLet p[i,j] be true if and only if X[i…j] is a palindrome.Obviously, we need 2D, though i &lt;= j. It’s like a half plane. If X[i] = X[j], p[i,j] is true iff p[i+1,j-1] is true. If X(i) = X(j), p[i,j] = p[i+1,j-1] Order: from (i,j) to (i+1,j-1) it’s a diagonal path. Base If i = j, p[i,j] = true pseudo-code12345678910111213141516let p[0...n,0...n] be a new array of all falsemax = 1 for i = 1 to n-1 do p[i,i] = true if X(i) = X(i+1) then p[i,i+1] = true max = 2% updating along diagonal% started from the third diagonalfor k = 3 to n do for i = 1 to n-k+1 do j = i+k-1 if p[i+1,j-1] = true and X(i) = X(j) then p[i,j] = true max = kreturn max AnalyzeRunning time: 𝑂(𝑛^2^)Space: 𝑂(𝑛^2^) but can be improved to 𝑂(𝑛) Optimal BST Given n keys a~1~ &lt; a~2~ &lt; … &lt; a~n~, with weights f(a~1~), … , f(a~n~), find a binary search tree T on these n keys such thatB(T) = sum{ f(a~i~)*(d(a~i~)+1) } i from 1 to nis minimized, where d(a~i~) is the depth of a~i~. RecurrenceLet T~i,j~ be some tree on the subset of nodes a~i~ &lt; a~i+1~ &lt; … &lt; a~j~Define w[i,j] = f(a~i~) + … + f(a~j~)The cost is defined as B(T~i,j~) = sum{ f(a~i~)*(d(a~i~)+1) } from i to jDefine e[i,j] = optimal value of B(T~i,j~) The optimal cost of T~i,j~ isThe optimal cost of left subtree + The optimal cost of right subtree + root’s weight e[i,j] = e[i,k-1 + e[k+1,j] +w[i,j] To find k, try every value between i and j to figure out the min. e[i,j] = min{ e[i,k-1 + e[k+1,j] +w[i,j] } for i&lt;=k&lt;=j Order: (i,j) (i,k-1) (k+1,j) Base e[i,j]= 0 for i&gt;je[i,i] = f(a~i~) for all i pseudo-code1234567891011121314151617181920212223242526Optimal-BST(a,n):let e[1...n,1...n],w[1...n,1...n],root[1...n,1...n] be new arrays of all 0for i = 1 to n w[i,i] = f(a(i)) for j = i + 1 to n % complete the w[] table w[i,j] = w[i,j-1] + f(a(i))for l = 1 to n for i = 1 to n-l+1 j = i+l-1 e[i,j] = inf % find k minimizes e[] for k = i to j t = e[i,k-1]+e[k+1,j]+w[i,j] if t &lt; e[i,j] then e[i,j] = t root[i,j] = kreturn Construct-BST(root,1,n)Construct-BST(root,i,j):if i &gt; j then return nilcreate a node zz.key = a[root[i,j]]z.left = Construct-BST(root,i,root[i,j]-1)z.right = COnstruct-BST(root,root[i,j]+1,j)return z AnalyzeRunning time: Optimal 𝑂(𝑛^3^) Construct 𝑂(𝑛^2^)Space 𝑂(𝑛^2^)]]></content>
      <categories>
        <category>Algorithm and Graph</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>DP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Finite State Machine]]></title>
    <url>%2F2018%2F12%2F08%2FFinite-State-Machine%2F</url>
    <content type="text"><![CDATA[State Machine State: A set of particular condition that the machine is in at a specific time FSM is a generic synchronous sequential circuit FSM has finite state memory, inputs &amp; outputs State memory is implemented using flip-flops State transition logic implemented using combinational circuit Output logic implemented using combinational circuit Output depends on state only - Moore Output depends on state and input - Mealy State equationsDescribe the behavior of a clocked sequential circuit algebraically.e.g. A(t+1) = D~A~(t) = A(t)x(t) + B(t)x(t)Simple form:A(t+1) = Ax + Bx or A^+^ = Ax + Bx State Diagram and Transition Tables The diagram is a Mealy Machine Moore Machine vs. Mealy MachineMoore MachineThe output value is inside the state bubbles.Outputs are function solely of the current states.Outputs change synchronously with states. Mealy MachineThe output value is on the transition edge.Outputs depend on state AND inputsChange of inputs causes an immediate change of outputs. Example Basic Design Steps of FSM Understand the Specificationswith a block diagram Obtain an abstract specification of the FSMin state-transition diagram or table Perform state reductionequivalent states can be merged Perform state assignmentassign binary values to the state in a way that next-state logic can be simplified Choose FF to implement the FSM state register D-FF : Q+ = D T-FF : Q^+^ = TQ’ + T’QT = 0 hold ;T = 1 toggle; JK-FF: Q^+^ = JQ’ + K’Q| JK | Data | function || :—: | :—: | :———: || 0/0 | 1 | hold || 0/1 | 0 | reset || 1/0 | Q | set || 1/1 | Q’ | toggle | Implement the FSMdesign of next-state and output logic Happy DEBUGGING!! FSM Implementation Procedure Start with a state diagram (bubble diagram) Describes the Finite State Machine according to the specification Reduce the number of states if necessary/possible(state reduction) equivalent-states Two internal states are said to be equivalentif for each input combination they give exactly the same output AND send the circuit to the same(equivalent) state. Decide on the State Encoding (how many flip-flops to use and what should be the FF outputs be for each state) Produce the binary-code state table. Decode what kind of FFs to use. D-type FFs are normally used (JK or T are more complicated and may give you smaller circuit if you play with TTLs) Determine the FF input equations (use FF excitation rules for JK and T type FFs) and general output equations from the transition tables Implement the next state logic, output logic using combinational circuit techniques Draw the complete logic diagram]]></content>
      <categories>
        <category>School Notes</category>
      </categories>
      <tags>
        <tag>FSM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VHDL]]></title>
    <url>%2F2018%2F12%2F08%2FVHDL%2F</url>
    <content type="text"><![CDATA[EntityIdentify a distinct logic block Consists of the input and output ports (I/O pins) Each port can have several variables 1234entity nand2 isport (a,b : in std_logic; y : out std_logic);end nand2; Ports can be in (read), out (write), inout (bi-directional) Std_logic is the type of signal being carried at the ports Std_logic can have values such as ‘0’, ‘1’, ‘X’, ‘Z’, ‘-’ and others.(‘ z ‘ means high impedance (tristate)) Another signal type is “bit” which only assumes binary values of ‘0’ and ‘1’. ArchitectureFollow immediately after the entity declaration,to define the internal operation (function) of the logic module Defines the relationship between the input and output signals May have internal signals in the definition AN entity can have several different architecture specifications to describe different views or different levels 12345678entity inverter_gate is port (A: in std_logic; Z: out std_logic);end inverter_gate;architecture DATAFLOW of inverter_gate isbegin z &lt;= not A after 10 ns;end DATAFLOW; 1234567Entity OR3 isport (I1,I2,I3: in std_logic; O: out std_logic);end OR3;architecture BEHAVIOR of OR3 isbegin O &lt;= I1 or I2 or I3;end BEHAVIOR; Internal signalsused to simplify the model ordefine connections between sub-components inside the architecture 1234architecture example of special_mus is signal control, tmp : std_logic;beginend example; Concurrent Statements Signal Assignments Component Instantiations for structural description) Processes IN ORDER Signal Assignments1C &lt;= '0'; Delayed1c &lt;= A and B after 10ns; --Only for simulation. Selected (outside PROCESS)connect target to many cases of one source. 1234with sel select DAta_out &lt;= a when '0', b when '1', 'X' when others; Conditional (outside PROCESS)connect target to many cases of several sources. 123Y &lt;= a when en = ‘1’ else ‘Z’ when en = ‘0’ else ‘X’; Component Instantiations for structural description123COMPONENT xor_gate PORT ( A, B: IN STD_LOGIC; C: OUT STD_LOGIC);END COMPONENT; Processes IN ORDERIf-else Branchmany signals many cases.1234567if sth = '0' then A = '1'; B = '0'; -- IN-ORDER processeselsif sth = '1' then -- optional B = '1'; C = '0'; -- optionalelse -- IMPORTANT! C = '1';end if； case-when Branchone signal many cases.12345case sth is when '0' =&gt; A = '1'; B = '0'; when '1' =&gt; B = '1'; C = '0'; when others =&gt; C = '1'; -- IMPORTANT!end case; Variable and SignalThe variable is updated without any delay as soon as the statement is executed.Variables must be declared inside a process (and are local to the process).Assignment := executed sequentially! 123456789101112131415architecture VAR of EXAMPLE is signal TRIGGER, RESULT: integer :=0;begin process variable variable1: integer := 1; variable variable2: integer := 2; variable variable3: integer := 3; begin wait on TRIGGER; variable1 := variable2; --2 variable2 := variable1 + variable3; --2+3=5 variable3 := variable2; --5 RESULT &lt;= variable1 + variable2 + variable3; --2+5+5 end process;end VAR; The signal is updated after a time delay (delta delay if no delay is specified).Signals must be declared outside the process.Assignment &lt;= executed concurrently! 123456789101112131415architecture SIGN of EXAMPLE is signal TRIGGER, RESULT: integer :=0; signal signal1: integer := 1; signal signal2: integer := 2; signal signal3: integer := 3;begin process begin wait on TRIGGER; signal1 &lt;= signal2; --2 signal2 &lt;= signal1 + signal3; --1+3 signal3 &lt;= signal2; --2 RESULT &lt;= signal1 + signal2 + signal3; --1+2+3 end process;end VAR; Dataflow architectureSpecify input/output relations in Boolean expression or conditional statements 1234567891011ENTITY 2_to_4_decoder IS PORT (A, B, E: IN STD_LOGIC; D: OUT STD_LOGIC_VECTOR (3 downto 0);END 2_to_4_decoder;ARCHITECTURE dataflow OF 2_to_4_decoder ISBEGIN D(0) &lt;=‘0’ WHEN (A=‘0’ AND B=‘0’ AND E=‘0’) ELSE ‘1’; D(1) &lt;=‘0’ WHEN (A=‘0’ AND B=‘1’ AND E=‘0’) ELSE ‘1’; D(2) &lt;=‘0’ WHEN (A=‘1’ AND B=‘0’ AND E=‘0’) ELSE ‘1’; D(3) &lt;=‘0’ WHEN (A=‘1’ AND B=‘1’ AND E=‘0’) ELSE ‘1’;END dataflow; Structural architectureDescribes a set of interconnected components. 1234567891011121314151617ARCHITECTURE structural OF four_bit_adder_sub IS COMPONENT four_bit_adder PORT ( A: IN STD_LOGIC_VECTOR (3 downto 0); B: IN STD_LOGIC_VECTOR (3 downto 0); C0: IN STD_LOGIC; C4: OUT STD_LOGIC; S: OUT STD_LOGIC_VECTOR (3 downto 0)); END COMPONENT; COMPONENT xor_arrays PORT ( X: IN STD_LOGIC_VECTOR (3 downto 0); Z: IN STD_LOGIC; Y: OUT STD_LOGIC_VECTOR (3 downto 0)); END COMPONENT; signal Y: STD_LOGIC_VECTOR (3 downto 0);BEGIN Block1: xor_arrays PORT MAP (B, M, Y); Block2: four_bit_adder PORT MAP (A, Y, M, C, S);END structural; Behavioral architectureAny change in the values of Sensitivity List will cause immediate execution of the process 1234567891011121314151617ENTITY mux4 ISPORT ( S: IN STD_LOGIC_VECTOR (1 downto 0); I: IN STD_LOGIC_VECTOR (3 downto 0); Y: OUT STD_LOGIC);END mux4;ARCHITECTURE behavioral OF mux4 ISBEGIN PROCESS (S, I) -- Sensitivity List BEGIN CASE S IS WHEN “00” =&gt; Y &lt;= I(0); WHEN “01” =&gt; Y &lt;= I(1); WHEN “10” =&gt; Y &lt;= I(2); WHEN “11” =&gt; Y &lt;= I(3); END CASE; END PROCESS;END behavioral;]]></content>
      <categories>
        <category>School Notes</category>
      </categories>
      <tags>
        <tag>VHDL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[COMP2611 Final Review]]></title>
    <url>%2F2018%2F12%2F07%2FCOMP2611-Final-Review%2F</url>
    <content type="text"><![CDATA[@[TOC] Arithmetic for ComputersOverflow Detection Operation Sign bit of X Sign Bit of Y Sign Bit of Result X+Y 0 0 1 X+Y 1 1 0 X-Y 0 1 1 X-Y 1 0 0 Multiplication Division PipelineStages:IF : Fetch the instructions from meomryID : Instruction decode &amp; register readEX : Perform ALU operationMEM : Memory access (if necessary)WB : Write result back to register Registers:located between the stages:​ IF/ID, ID/EX, EX/MEM, MEM/WB Control:IF : no control signalsID : no control signalsEX : RegDst, ALUOP, ALUSrcMEM : Branch, MemRead, MemWriteWB : MenToReg, RegWrite Hazards:cause: Data dependence and Control dependence.types: Structural hazards, Data hazards, Control hazards Structural hazardsConflict for use of memory(MEM/IF) and registers(WB/ID). Solution: separate instruction and data memories Fact: Register very fast. Registers can Write during 1st half of clock cycle and Read during 2nd half. Data hazards add $s0, $t0, $t1sub $t2, $s0, $t3 Solution: Forwarding (partial, can’t solve below code) lw $s0, 20$(t1)sub $t2, $s0, $t3 Scheduling (assume forwarding is used) Control hazardsWhen we need to beq , bne operations Solution: Fetch instruction after branch. If wrong, flush them away. Add comparator to compare earlier Datapath with HazardsData forwardingTwo types forwarding: EX/MEM -&gt; ID/EX and MEM/WB -&gt; ID/EXUsing two multiplexers to decide what is the input of operands A and B of the ALU.note: A is for Rs. B is for Rt. EX forwarding:123456if (EX/MEM.RegWrite and (EX/MEM.RegisterRd ≠ 0) and (EX/MEM.RegisterRd = ID/EX.RegisterRs )) ForwardA = 10 if (EX/MEM.RegWrite and (EX/MEM.RegisterRd ≠ 0) and (EX/MEM.RegisterRd = ID/EX.RegisterRt )) ForwardB = 10 MEM forwarding (only when NOT EX forwarding ):12345678910if (MEM/WB.RegWrite and (MEM/WB.RegisterRd ≠ 0) and not (EX/MEM.RegWrite and (EX/MEM.RegisterRd ≠ 0) and (EX/MEM.RegisterRd = ID/EX.RegisterRs ))and (MEM/WB.RegisterRd = ID/EX.RegisterRs )) ForwardA = 01 if (MEM/WB.RegWrite and (MEM/WB.RegisterRd ≠ 0) and not (EX/MEM.RegWrite and (EX/MEM.RegisterRd ≠ 0) and (EX/MEM.RegisterRd = ID/EX.RegisterRt ))and (MEM/WB.RegisterRd = ID/EX.RegisterRt )) ForwardB = 01 Load-use detectionWhen Load-use hazard occur, we can do nothing but stall a clock cycle.To detect it: 123Load-use hazard = ID/EX.MemRead and ((ID/EX.RegisterRt = IF/ID.RegisterRs ) or (ID/EX.RegisterRt = IF/ID.RegisterRt )) How to Stall Force control values in ID/EX register to 0 :​ EX, MEM and WB do EX, MEM and WB do nop (no -operation) Prevent update of PC and IF/ID registerUsing instruction is decoded againFollowing instruction is fetched again1-cycle stall allows MEM to read data for lw (with forwarding) Data Hazard when branchIn pipeline datapath, branch target address calculation is executed in another ALU NOT in EXE stage. It is executed during ID staged. ID Stage: Target address calculator, Register file, Register comparator. add $1, $2, $3add $4, $5, $6add $7, $8, $9 # another instructionbeq $1, $4, target Can resolve using forwarding. From MEM/WB and EXE/MEM to ID add $1, $2, $3add $4, $5, $6beq stalled…beq $1, $4, target Need one cycle stalled. lw $1,addrbeq stalled…beq stalled…beq $1, $0, target Need two cycles stalled. MemoryRAM(Random Access Memory) technology includes two types: Static RAM — mostly used for cache0.5ns-2.5ns, $2000 -$5000 per GBconsists only Transistors Dynamic RAM(DRAM) — mostly used for main memory 50ns - 70ns, $20-$75 per GB consists of Transistor and Capacitor Magnetic disk: 5ms - 20ms, $0.2-$2 per GB Disk Sectors and AccessesEach sector records:Sector IDData (512 bytes, 4096 bytes proposed)Error correcting code (ECC)Synchronization fields and gaps Access to a sector involves:Queuing delay if other accesses are pendingSeek: move the headsRotational latencyData transferController overhead Principle of Locality Programs access a small proportion of their address space at any time Temporal locality Items accessed recently are likely to be accessed again soon Spatial localityItems near those accessed recently are likely to be accessed soon This property is the KEY to memory hierarchy! Memory HierachyInitially,Instructions and data are loaded into DRAM from disk. Upon first access,A copy of the referenced instruction or data item is kept in cache In subsequent accesses,First, look for the requested item in the cache​ If the item is in the cache, return the item to the CPU​ If NOT in the cache, look it up in the memory We can say: If not found in this level, look it up at next level until foundKeep (cache) a copy of the found item at this level after use CacheEach memory locations is mapped to ONE location in the cache. average latency = hit + miss= r*t1 + ((1-r)t1 + rt2) = t1 + (1-r)t2NOT r*t1 + (1-r)t2 Three basic organizations: Direct-mapped( one memory block to one possible cache block) Set-mapped( one memory block to one set of possible cache blocks) Fully-mapped( one memory block to all possible cache blocks) Direct Mapped CacheIf the number of cache blocks (N) is a power of 2; N=2^mcache_location = the low-order m bits of block addresse.g. map the value1200 to a 8 blocks, 32 byte/block cache. Block address = 1200/32 = 37Block number = 37 % 8 = 5 Disadvantage:block access sequence: 100011, 001011, 100011later arrival will kill out previous one. called cache conflict. Tags and Valid BitsTags: decide which particular block is stored in a cache location.Store block address as well as the data.Only need the high-order bits.tags size= original address size- block size- blocks number(binary) - 1(valid bit) Valid Bits: decide whether the data exists. Initially 0. Consider a direct-mapped cache with 8 cache frames and a block size of 32 bytesMemory (byte) address generated by CPU|Block address|Hit or miss|Assigned cache block—-|—-|—|—-0010 1100 0010|0010 110|Miss|1100011 0100 0000|0011 010|Miss|0100010 1100 0100|0010 110|Hit|1100010 1100 0010|0010 110|Hit|1100010 0000 1000|0010 000|Miss|0000000 0110 0000|0000 011|Miss|0110010 0001 0000|0010 000|Hit|0000010 0100 0001|0010 010|Miss|010 Associate CacheFully associative(FA):Each block can be placed anywhere in the cache.pros: No cache conflict. But still have misses due to size.cons: Costly (hardware and time) N-way Set associative(SA):Each block can be placed in a certain number(N) of cache locations.A good compromise between DM &amp; FA Block Replacement Random Least recently used(LRU):Upon miss:Replace the LRU with missed address -&gt; Move the miss address to MRU positionUpon hit:Move the hit address to MRU position -&gt; Pack the rest Deal with Dirty DataWrite-backCPU only write to cache.CPU can write individual words at the rate of the cache.Multiple writes to a block are merged into one write to main memory.more and more caches use this strategy. Write-throughCPU write both on cache and memory.(memory always up-to-date)]]></content>
      <categories>
        <category>School Notes</category>
      </categories>
      <tags>
        <tag>MIPS</tag>
        <tag>assemble</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hashing]]></title>
    <url>%2F2018%2F12%2F07%2FHashing%2F</url>
    <content type="text"><![CDATA[Hash TableA hash table is an array of some fixed size,containing all the data items.Each item has a key search is performed based on the keys.Each key is mapped into some position in the array in the range 0 to m − 1, where m is thearray size.The mapping is called hash function. Hashing table is a data structure that supports: searching insertion deletion The implementation of hash tables is called hashing.Hashing is a technique which allows the executions of above operations in constant time on average.Unlike other data structures such as linked list or binary trees, data items are generally not ordered in hash tables.As a consequence, hash tables don’t support the following operations: find_min and find_max finding successor and predecessor reporting data with a given range listing out the data in order Hashing FunctionDesignA simple and reasonable strategy: h(k) = k mod m. Its a good practice to set the table size m to a prime number. h(key) =(key[0] + 37*key[1] + 37^2*key[2] + … ) mod m Handling collisionMake hash table an array of linked lists Seperate ChainingInsertionTo insert a key k: Compute h(k)If T(h(k)) contains nullptr , initial this table entry to point to linked list node of kk .If T(h(k)) contains non-nullptr, add k to the beginning of the list. DeletionTo delete a key k: Compute h(k) to determine which list to traverse.Search for the key k, in the list that T(h(k)) points to.Delete the item with key k if it is found. Open addressingInstead of putting keys of the same hash table into a chain, open addressing will relocate the key k to be inserted if it collides with an existing key. Linear probing f(i) = ihi(k) = (hash(k) + i) mod m Disadvantage: fall into cluster quadratic probing f(i) = i^2^hi(k) = (hash(k) + i^2^) mod m Disadvantage: second cluster… same key same probe steps. double hashing f (i) = i × hash2(k)h~i~(k) = (hash(k) + i × hash~2~(k)) mod m hash~2~(k) must be relatively prime to the table size m.Otherwise, we will only be able to examine a fraction of the table entries.]]></content>
      <categories>
        <category>School Notes</category>
      </categories>
      <tags>
        <tag>data structure</tag>
        <tag>hashing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AVL Trees]]></title>
    <url>%2F2018%2F12%2F06%2FAVL-Trees%2F</url>
    <content type="text"><![CDATA[(All codes below are written by Dr. Desmond) AVL(Adelson-Velsky and Landis) TreesEvery sub-tree of an AVL tree is itself an AVL tree.(An empty tree is an AVL tree too.)123456struct AVLNode&#123; T data; int height; // Important! AVLNode* left; AVLNode* right; &#125; AVL Tree Searchingsame as BST searching AVL Tree InsertionInsertion may violate the AVL tree property in 4 cases: Insertion into the right sub-tree of the right childLeft(anti-clockwise) rotation [single rotation] Insertion into the left sub-tree of the left childRight(clockwise) rotation [single rotation] Insertion into the right sub-tree of the left childLeft-right rotation [double rotation] Insertion into the left sub-tree of the right childRight-left rotation [double rotation] !!! Distinguish L/R of subtree or L/R of child !!! First insert the node to right place, then balance it by rotation.123456789AVLNode&lt;T&gt;* AVL&lt;T&gt;::insert(AVLNode&lt;T&gt;* p, const T&amp; d)&#123; if( !p ) return new AVLNode&lt;T&gt;(d); // Empty AVL tree if( d &lt; p-&gt;data ) p-&gt;left = insert(p-&gt;left, d); // Recursion on the left sub-tree else p-&gt;right = insert(p-&gt;right, d); // Recursion on the right sub-tree return balance(p);&#125; RotationSingle rotation operate on the node, replace original node by its childDouble rotation first operate on the child, then on the node, replace original node by its grandchild. 1234567891011121314151617181920212223242526272829303132AVLNode&lt;T&gt;* AVL&lt;T&gt;::rotateRight(AVLNode&lt;T&gt;* p)&#123; AVLNode&lt;T&gt;* pl = p-&gt;left; p-&gt;left = pl-&gt;right; pl-&gt;right = p; updateHeight(p); updateHeight(pl); return pl;&#125;AVLNode&lt;T&gt;* AVL&lt;T&gt;::rotateRightLeft(AVLNode&lt;T&gt;* p)&#123; rotateRight(p-&gt;right); return rotateLeft(p);&#125;AVLNode&lt;T&gt;* AVL&lt;T&gt;::balance(AVLNode&lt;T&gt;* p)&#123; h-&gt;height = max(h-&gt;right-&gt;height,h-&gt;left-&gt;height); // heightDiff() return (right subtree height) - (left subtree height) if( heightDiff(p) == 2 )&#123; if( heightDiff(p-&gt;right) &lt; 0 ) // if need double rotation p-&gt;right = rotateRight(p-&gt;right); return rotateLeft(p); // single rotation &#125; if( heightDiff(p) == -2 )&#123; if( heightDiff(p-&gt;left) &gt; 0 ) // if need double rotation p-&gt;left = rotateLeft(p-&gt;left); return rotateRight(p); // single rotation &#125; return p;&#125; AVL Tree DeletionThe idea is same as BST.When delete node with two children, the following code delete the node andrise the min node up.Then balance the whole tree.123456789101112131415161718192021222324252627282930313233AVLNode&lt;T&gt;* AVL&lt;T&gt;::findMin(AVLNode&lt;T&gt;* p) const&#123; return p-&gt;left ? findMin(p-&gt;left) : p;&#125;// NOT delete the Min-node!!AVLNode&lt;T&gt;* AVL&lt;T&gt;::removeMin(AVLNode&lt;T&gt;* p)&#123; if(p-&gt;left == 0) // If it's the min node, not return itself return p-&gt;right; // Return the second min means removeMin! p-&gt;left = removeMin(p-&gt;left); // Recursion on the left sub-tree return balance(p);&#125;AVLNode&lt;T&gt;* AVL&lt;T&gt;::remove(AVLNode&lt;T&gt;* p, const T&amp; d) &#123; if( !p ) return 0; // Item is not found; do nothing if( d &lt; p-&gt;data ) p-&gt;left = remove(p-&gt;left,d); // Recursion on the left sub-tree else if( d &gt; p-&gt;data ) p-&gt;right = remove(p-&gt;right,d); // Recursion on the right sub-tree else &#123; // Item is found AVLNode&lt;T&gt;* pl = p-&gt;left; AVLNode&lt;T&gt;* pr = p-&gt;right; delete p; // Remove the node with value d if( !pr ) return pl; // Return left sub-tree if no right sub-tree AVLNode&lt;T&gt;* min = findMin(pr); // Find min. node of the right sub-tree min-&gt;right = removeMin(pr); // Did NOT delete the min node on right sub-tree min-&gt;left = pl; return balance(min); // Balance this node &#125; return balance(p); // Balance this node&#125; Explanationp-&gt;left = remove(p-&gt;left,d);Connect between parent and child. So no need to store parent pointer.delete p;Truly delete node with required data. But store its left and right nodes.Later return min of right sub-tree to its parent node. No memory leak.min-&gt;right = removeMin(pr);Return from the second min node and balanced from bottom up to the deleted node’s right child.Did not truly delete the min node. It should already be stored by findMin() function. Also refer here]]></content>
      <categories>
        <category>I don&#39;t know about C++</category>
      </categories>
      <tags>
        <tag>data structure</tag>
        <tag>Cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Trees, Binary Trees, Binary Search Trees]]></title>
    <url>%2F2018%2F12%2F05%2FTrees-Binary-Trees-Binary-Search-Trees%2F</url>
    <content type="text"><![CDATA[Binary TreeInorder traversalpreorder traversalpostorder traversal Binary Search TreeBST InsertionAlways insert element at bottom as leaf.Remember to check if the element already exists in the tree. Recursion12345678910bool insert(const T&amp; x, Node*&amp; n ) // pass by referenceNode* insert(const T&amp; x, Node* n ) // pass by value need return pointer&#123; // base case 1: reach the node beyond leaf if(!n) &#123;n-&gt;x = new T(x);return true / new T(x);&#125; // base case 2: the data already exists if(n-&gt;x == x) return false / nullptr ; if(x &lt; n-&gt;x) return insert(x,n-&gt;left); else return insert(x,n-&gt;right);&#125; The insert function parameter Node*&amp; is a reference.We always pass reference to it, thought the value of the reference may be nullptr.e.g. insert(x,t-&gt;left) .In this case, t always refers to a Node*. Iteration12345678910111213141516bool insertIterative(const T&amp; x, Node* p ) // pass by value&#123; // A new pointer to refer to the leaf Node* pp = nullptr; for(;p!=nullptr;) &#123; // already exists if(p-&gt;x == x) &#123;return false;&#125; pp = p; // save parent for reference if(p &lt; p-&gt;x) p = p-&gt; left; else p = p-&gt;right; &#125; // root is nullptr if(!pp) root = new T(x); else pp = new T(x);&#125; We only need to know the value of the root of the tree.But we need to record the reference of the parent of the insertion node. BST Searchpublic interface: 1234567891011bool contain(const T&amp; x) const&#123; Node* p = root; Node* pp = nullptr; // Non-recursion method COMMON return search(x,p,pp); // Recursion method return searchRecur(x,p) != nullptr; &#125; The implementation of search(x,p) and searchIterative(x,p,pp) is as below. Recursioncan NOT keep track of the parent node pointer.123456789Node* searchRecur(const T&amp; x, Node* n ) // pass by value&#123; // base case 1: reach the node beyond leaf if(!n) &#123;return nullptr;&#125; // base case 2: find the data if(n-&gt;x == x) return n; if(x &lt; n-&gt;x) return search(x,n-&gt;left); else return search(x,n-&gt;right);&#125; Iteration1234567891011bool search(const T&amp; x, Node*&amp; n, Node*&amp; pn )// pass by reference&#123; for(;n!=nullptr;) &#123; if(n-&gt;x == x) &#123;return true;&#125; pn = n; if(x &lt; n-&gt;x) n = n-&gt; left; else n = n-&gt;right; &#125; return false;&#125; Can keep track of parent node pointer.Note the Node*&amp; n and Node*&amp; pn is pas by reference.They must be created before calling the function BST deletionneed findMin() function to help. 123456Node* findMin(Node* p)&#123; if(!p)return nullptr; while(p-&gt;left)p=p-&gt;left; return p;&#125; Delete a node with no child : pointer: current parentSimply delete it and make its parent’s original pointer to it nullptr Delete a node with one child : pointer: current parent childPass its pointer to the only child to its parent’s pointer to it. Then delete it. Delete a node with two child : pointer: current min/max parent of min/maxOverride its data to the max of left or min of rightActually delete the min/max node of the BST, which has no child Recursion1234567891011121314151617181920212223242526272829303132bool remove(const T&amp; x,Node*&amp; n) // pass by reference&#123; // Base case: NOT found if(!n) return false; // Recursive steps if(x&lt;n-&gt;x) return remove(x,n-&gt;left); if(x&gt;n-&gt;x) return remove(x,n-&gt;right); // node with no child if(!n-&gt;left &amp;&amp; !n-&gt;right) &#123; delete n; n = nullptr; &#125; // node with two children else if(n-&gt;left &amp;&amp; n-&lt;right) &#123; Node* rightMin = findMin(n-&gt;right); n-&gt;x = rightMin-&gt;x; // always true remove(n-&gt;x,rightMin); &#125; // node with only one child else &#123; Node* child = root-&gt;left?root-&gt;left:root-&gt;right; // save &amp;n to curr, later delete Node* curr = n; n = n-&gt;child; delete curr; &#125; return true;&#125; IterationNeed the parent node pointer of Min node.Hard to implement.]]></content>
      <categories>
        <category>I don&#39;t know about C++</category>
      </categories>
      <tags>
        <tag>data structure</tag>
        <tag>Cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Static Variables]]></title>
    <url>%2F2018%2F12%2F05%2FStatic-Variables%2F</url>
    <content type="text"><![CDATA[Static variablesGlobal Scope created only once in a program. reside on the static data region of the loaded program. have a lifetime across the entire run of a program. still may have limited scope: file, function, class. Function Scope initialized only once regardless how many times the function is called. retain their values across the function calls. can be accessed only inside the function. Class Scope variables in different objects are actually one variable. initialize variable must be done in global scopecannot initialize it inside the class. NOT in any function! Not in main(), either!NO keyword statice.g. 1234&gt; class A &#123;static int a;&#125;;&gt; int A::a = 10;&gt; int main()&#123;&#125;&gt; variable exists even if no class object is created. Static FunctionsGlobal Functions almost same as static variables. Member Functions do not have the implicit this pointer like regular non-static member functions. may be used even when there are no objects of the class! can only make use of static data members of the class. cannot be const nor virtual functions. can be defined outside the class declaration NO keyword static e.g. 1234&gt; class A &#123;static void f();&#125;;&gt; void A::f()&#123;&#125;&gt; int main()&#123;&#125;&gt; &gt;&gt;]]></content>
      <categories>
        <category>I don&#39;t know about C++</category>
      </categories>
      <tags>
        <tag>Cpp</tag>
        <tag>static variable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Inheritance and Polymorphism]]></title>
    <url>%2F2018%2F12%2F05%2FInheritance-and-Polymorphism%2F</url>
    <content type="text"><![CDATA[Inheritance_Inheritance_: describe “is-a relationship”_Polymorphism_: derived class can perform like base class(object,pointer,reference) _Construction Order_: from inner to outer_Destruction Order_: from outer to inner member access control_public_: member functions of the class(inner)any member funtions of other classes(other class)any global functions(outside) _protected_: member functions and _friends_ of the classmember functions and _friends_ of its _derived classes_NOT for outside functions _private_: member functions and friends of the class Without inheritance, private and protected have exactly the same meaning. public protected private inheritance inheritance\member public protected private public inheritance public protected private protected inheritance protected protected private private inheritance private private private Public inheritance implements the “is-a” relationship Private inheritance is similar to “has-a” relationship Friendfriend of Base is not friend of Derived PolymorphismDynamic Binding&amp;Virtual FunctionOnce a method is declared virtual in the base class, it is automatically virtual in all directly and indirectly derived classes. Even if derived classed do not announce it’s virtual functions. Virtual destructor can make deleting a base pointer to derived object operate correctly. Do not rely on the virtual function mechanism during the execution ofa constructor. Similarly, if a virtual function is called inside the base class destructor,it represents base class’ virtual function: when a derived class is beingdeleted, the derived-specific portion has already been deleted beforethe base class destructor is called. Abstract Base Class(ABC):NO object of ABC can be created Its derived classes must implement the pure virtual functions. ABC is just an interface.]]></content>
      <categories>
        <category>I don&#39;t know about C++</category>
      </categories>
      <tags>
        <tag>Cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ Memory Leak]]></title>
    <url>%2F2018%2F11%2F26%2FC-Memory-Leak%2F</url>
    <content type="text"><![CDATA[Memory detectionIn Windows using Visual Studiohere Open source toolshere]]></content>
      <categories>
        <category>I don&#39;t know about C++</category>
      </categories>
      <tags>
        <tag>Cpp</tag>
        <tag>memory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AI Chap.3 Searching]]></title>
    <url>%2F2018%2F06%2F28%2FAI-Chap-3-Searching%2F</url>
    <content type="text"><![CDATA[Describe problem formallystate: initial state:actions: each state corresponds to a set of available actionstransition model: return the result state of an action from the previous stategoal test:path cost: the essence of a solution is a sequence of actions that lead from the initial state to the goal state. Problem formulationincremental formulation: e.g. 8-queens puzzle. Initial state: no queen; Action: add a queen.complete-state formulation: e.g. 8-queens puzzle. Initial state: 8 queens; Action: move a queen. Searchsearch algorithms all use a search tree data structure with nodes. noden.state: correspond state in state space;n.parent: the node in the search tree that generated this node;n.action: the action that was applied to the parent to generate this node;n.path-cost: succeeded from parent; other conceptsexpanding: apply each legal action to the current state, thereby generating a new set of states.parent node ; child node ; leaf node: a node with no child nodefrontier(open list): the set of all leaf nodes avaiable for expansionexplored set(close list): the set of expanded nodesthe frontier separates the state space into explored region and unexplored regionrepeated state ; loopy path: a special case of the more general concept of redundant path Uninformed(blind) searchtree searchnot remember history causes loopy paths which is a special case of redundant path graph searchadd explored set(close list) to remember breadth-first searchFIFO queue; expand shallowest node;time complexity: O(b^d) (test while generating) O(b^(d+1)) (test while selected)space complexity: all nodes uniform-cost searchpriority queue; expand cheapest node;test while selected because while generating it may not be the optimal one.time complexity: e be the minimum step-cost,C* be the optimal cost. O(b^floor(1+(C*/c)))space complexity: near nodes depth-first searchLIFO stack; first to deepest node that has no successors;common to implement with a recursive function, recursive depth-first search(RDFS)time complexity: O(b^m^)space complexity: m is the maximum depth. O(bm)or O(m)( backtracking search in which expanded node remembers which successor to generate next) depth-limited searchinfinite state space cause depth-first search fall. It can be alleviated by a depth limit l. iterative deepening depth-first searchoften used in combination with depth-first search to find the best depth limit.gradually increase the depth limit till the goal is found.upper levels generate multiple times: N(IDS) = db+(d-1)b^2^+…+(1)b^d^ bidirectional search b^(d/2)^ + b^(d/2)^ &lt; b^d^ but action step must be reversible Summary Informed(Heuristic) searchgreedy best-first searchevaluates nodes by using just the heuristic function f(n) = h(n) time complexity: depends on heuristic function, worst O(b^m^), m is the maximum depth. space complexity: depends on heuristic function, worst O(b^m^), m is the maximum depth. A* search f(n) = g(n) + h(n) admissible heuristic: never overestimates the cost to reach the goalconsistent heuristic: the estimated cost of n is no greater than n’tree-search optimal if h(n) is admissible;graph-search optimal if h(n) is consistent absolute error: E=h*-h; relative error: e=(h*-h)/h time complexity: O(b^E^) or O(b^ed^)(constant step costs)space complexity: all nodes that f(n) &lt; C* Memory-bounded heuristic searchiterative-deepening A*(IDA*) cutoff = f(n) - g(n) - h(n) each iteration cutoff value is the smallest (f-g-h) of any node exceeded the cutoff on the previous iterationtoo little memory: between iteration, only retains cutoff = f-g-h recursive best-first search(RBFS)use f_limit variable to keep track of f-valueuse alternative variable to record the second-lowest f-value among successors (backed-up value)too little memory: each time change mind to alternative path, forget what it have done and regenerate nodes MA* and SMA*MA*(memory-bounded A*) and SMA*(simplified MA*) SMA* expands the best leaf until memory is full, drops the worst leaf node(highest h),like RBFS, SMA* back up the value of the forgotten node to its parent learning to search bettermetalevel state space: the internal(computational) state of a program that is searching in anobject-level state space: the real world problem Heuristic functionsFrom relaxed problemsignore some restriction rules and estimate the costrelaxed problem must be able to solved without searchwe can use more than one heuristic function like below: h(n) = max{h1(n), h2(n), …, hm(n)} From subproblems: Pattern databases subproblems: just solve part of the problem like going just half waypattern database: store these exact solution costs for every possible subproblem instancedisjoint pattern database: only consider partial cost of the subproblem that matters learning heuristics from experienceEach solution is an example for study.From these examples, a learning algorithm can be used to construct a function h(n)to predict solution costs for other states that arise during search.Inductive learning works best if supplied with features of a state relevant to predicting state’s valuethe feature is x1(n), x2(n), …, xm(n) after solved the problem, we found that h1(n), h2(n), …, hm(n) then we approach is to use a linear combination h(n) = c1*x1(n) + c2*x2(n) + … + cm*xm(n) Summary ![AI-Ch3-summary-2]/assets/AI-Chap-3-Searching/AI-Ch3-summary-2.png)]]></content>
      <categories>
        <category>AI study</category>
      </categories>
      <tags>
        <tag>searching</tag>
        <tag>AI</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dancing Video]]></title>
    <url>%2F2018%2F06%2F18%2FDancing-Video%2F</url>
    <content type="text"><![CDATA[Locking Judge Showhere Poppin Semi-final (win)here Poppin Final (lose)here]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
        <tag>dance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Notes]]></title>
    <url>%2F2018%2F06%2F08%2FLinux-notes%2F</url>
    <content type="text"><![CDATA[Keyboardhere About finding fileshere]]></content>
      <categories>
        <category>Linux Is Not UniX</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cpp Notes]]></title>
    <url>%2F2018%2F05%2F27%2FCpp-Notes%2F</url>
    <content type="text"><![CDATA[About private member1 在C+的类的成员函数中，允许直接访问该类的对象的私有成员变量2 在类的成员函数中可以访问同类型实例的私有变量量3 拷贝构造函数里，可以直接访问另外一个同类对象（引用）的私有成员4 类的成员函数可以直接访问作为其参数的同类型对象的私有成员 Below codes work!!123456789101112private: int data;public: void lookOtherConst(const A&amp; a)&#123; cout&lt;&lt;"other's private data is "&lt;&lt; a.data &lt;&lt;endl;&#125; void lookOtherReference(A&amp; a)&#123; cout&lt;&lt;"other's private data is " &lt;&lt;a.data&lt;&lt;endl;&#125; void lookOther(A a)&#123; cout&lt;&lt;"other's private data is " &lt;&lt;a.data&lt;&lt;endl;&#125; About f*cking consthere 前缀 与 后缀 运算符前缀：在表达式计算中使用值之前递增或递减，表达式的值与操作数的值不同后缀：在表达式使用值之后递增或递减， 表达式的值与操作数相同e.g.1234567int a=5,b =5;cout&lt;&lt;"a&lt;b++ = "&lt;&lt;bool(a&lt;b++)&lt;&lt;endl;cout&lt;&lt;"a&lt;++b = "&lt;&lt;bool(a&lt;++b)&lt;&lt;endl;output:a&lt;b++ = 0 a&lt;++b = 1]]></content>
      <categories>
        <category>I don&#39;t know about C++</category>
      </categories>
      <tags>
        <tag>Cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim Notes]]></title>
    <url>%2F2018%2F05%2F25%2FVim-notes%2F</url>
    <content type="text"><![CDATA[Neovim and vim-pluginA good blog link for both introduction of neovim and vim-plugin. search and substitutionhere fold and unfoldhere keyboard remaphere]]></content>
      <categories>
        <category>VIM is so hard to use</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Origin]]></title>
    <url>%2F2018%2F05%2F23%2FOrigin%2F</url>
    <content type="text"><![CDATA[Trust me, you would not like to read the shix inside, nor do I. Decrypt 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]]></content>
      <categories>
        <category>life</category>
      </categories>
  </entry>
</search>
